{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "digits_per_sequence = 5\n",
    "n_of_sequences = 60000\n",
    "output_path = './dataset/'\n",
    "\n",
    "emnist_dataset = datasets.EMNIST('./EMNIST', split = \"digits\", train = True, download = True)\n",
    "\n",
    "dataset_sequences = []\n",
    "dataset_labels = []\n",
    "a = []\n",
    "\n",
    "for i in range(n_of_sequences):\n",
    "  random_indices = np.random.randint(len(emnist_dataset.data), size=(digits_per_sequence,))\n",
    "  \n",
    "  random_digits_images = emnist_dataset.data[random_indices]\n",
    "\n",
    "  transformed_random_digits_images = []\n",
    "  \n",
    "  for img in random_digits_images:\n",
    "    _temp_img = transforms.ToPILImage()(img)\n",
    "\n",
    "    # fix EMNIST's transposed images\n",
    "    _temp_img = transforms.functional.rotate(_temp_img, -90, fill=(0,))\n",
    "    _temp_img = transforms.functional.hflip(_temp_img)\n",
    "\n",
    "    # crop pixels\n",
    "    # _temp_img = transforms.functional.crop(_temp_img, 0, 1, 28, 26)\n",
    "\n",
    "    # basic augmentation on each EMNIST digit\n",
    "    _temp_img = transforms.RandomAffine(degrees = 9,  scale=(0.85, 1.1))(_temp_img)\n",
    "    _temp_img = transforms.ToTensor()(_temp_img).numpy()\n",
    "\n",
    "    transformed_random_digits_images.append(_temp_img)\n",
    "\n",
    "  random_digits_images = np.array(transformed_random_digits_images)\n",
    "  \n",
    "  random_digits_labels = emnist_dataset.targets[random_indices]\n",
    "\n",
    "  random_sequence = np.hstack(random_digits_images.reshape(digits_per_sequence, 28, 28))\n",
    "  random_labels = np.hstack(random_digits_labels.reshape(digits_per_sequence, 1))\n",
    "\n",
    "  # dataset_sequences.append(random_sequence * 255)\n",
    "  dataset_sequences.append(random_sequence)\n",
    "  dataset_labels.append(random_labels)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "  os.makedirs(output_path)\n",
    "\n",
    "dataset_data = np.array(dataset_sequences)\n",
    "dataset_labels = np.array(dataset_labels)\n",
    "\n",
    "data_path = output_path + \"data_\" + str(digits_per_sequence) + \"_\" + str(n_of_sequences) + \".npy\"\n",
    "np.save(data_path, dataset_data)\n",
    "\n",
    "label_path = output_path + \"labels_\" + str(digits_per_sequence) + \"_\" + str(n_of_sequences) + \".npy\"\n",
    "np.save(label_path, dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data_path = './dataset/data_5_60000.npy'\n",
    "labels_path = './dataset/labels_5_60000.npy'\n",
    "\n",
    "data = np.load(data_path)\n",
    "data = torch.Tensor(data)\n",
    "labels = torch.IntTensor(np.load(labels_path).astype(int))\n",
    "\n",
    "seq_dataset = data_utils.TensorDataset(data, labels)\n",
    "print(int(len(seq_dataset)))\n",
    "print(int(len(seq_dataset) * 0.8))\n",
    "print(int(len(seq_dataset) * 0.2))\n",
    "train_set, test_set = torch.utils.data.random_split(seq_dataset, [int(len(seq_dataset) * 0.8), int(len(seq_dataset) * 0.2)])\n",
    "\n",
    "train_size = int(len(seq_dataset) * 0.8)\n",
    "test_size = int(len(seq_dataset) * 0.2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "number_of_printed_imgs = 5\n",
    "\n",
    "for batch_id, (x, y) in enumerate(train_loader):\n",
    "  for j in range(len(x)):\n",
    "    plt.imshow(x[j], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    print(y[j])\n",
    "    number_of_printed_imgs -= 1\n",
    "\n",
    "    if number_of_printed_imgs <= 0:\n",
    "      break\n",
    "\n",
    "  if number_of_printed_imgs <= 0:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for batchId, (i, j) in enumerate(train_loader):\n",
    "  x_train = i.numpy()\n",
    "  y_train = j.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for batchId, (i, j) in enumerate(test_loader):\n",
    "  x_test = i.numpy()\n",
    "  y_test = j.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train_loader)\n",
    "del(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_croped = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    a = x_train[i]\n",
    "    for j in range(x_train.shape[2]):\n",
    "        if j >= a.shape[1]:\n",
    "            continue\n",
    "        else:\n",
    "            if np.all(a[:, j] <= 0.2):\n",
    "                a = np.delete(a, j, 1)\n",
    "                j -= 1\n",
    "\n",
    "    train_croped.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_croped = []\n",
    "for i in range(test_size):\n",
    "    a = x_test[i]\n",
    "    for j in range(x_test.shape[2]):\n",
    "        if j >= a.shape[1]:\n",
    "            continue\n",
    "        else:\n",
    "            if np.all(a[:, j] <= 0.2):\n",
    "                a = np.delete(a, j, 1)\n",
    "                j -= 1\n",
    "\n",
    "    test_croped.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(x_train)\n",
    "del(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n",
    "z = 0\n",
    "\n",
    "for i in range(train_size):\n",
    "    if train_croped[i].shape[1] > max:\n",
    "        max = train_croped[i].shape[1]\n",
    "        z = i\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n",
    "z = 0\n",
    "\n",
    "for i in range(test_size):\n",
    "    if test_croped[i].shape[1] > max:\n",
    "        max = test_croped[i].shape[1]\n",
    "        z = i\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 1000\n",
    "z = 0\n",
    "\n",
    "for i in range(train_size):\n",
    "    if train_croped[i].shape[1] < min:\n",
    "        min = train_croped[i].shape[1]\n",
    "        z = i\n",
    "print(min)\n",
    "ind_train = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = 1000\n",
    "z = 0\n",
    "\n",
    "for i in range(test_size):\n",
    "    if test_croped[i].shape[1] < min:\n",
    "        min = test_croped[i].shape[1]\n",
    "        z = i\n",
    "print(min)\n",
    "ind_test = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_croped)):\n",
    "    train_croped[i] = train_croped[i] * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_croped)):\n",
    "    test_croped[i] = test_croped[i] * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "for i in range(len(train_croped)):\n",
    "    dummy = np.array(train_croped[i], dtype=np.uint8)\n",
    "    data = im.fromarray(dummy)\n",
    "    data.save('./train/tr%d.jpg' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "for i in range(len(test_croped)):\n",
    "    dummy = np.array(test_croped[i], dtype=np.uint8)\n",
    "    data = im.fromarray(dummy)\n",
    "    data.save('./test/te%d.jpg' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_croped)):\n",
    "    image = im.open('./train/tr%d.jpg' % (i))\n",
    "    new_image = image.resize((140, 28))\n",
    "    new_image.save('./train_reshaped/tr%d.jpg' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_croped)):\n",
    "    image = im.open('./test/te%d.jpg' % (i))\n",
    "    new_image = image.resize((140, 28))\n",
    "    new_image.save('./test_reshaped/te%d.jpg' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "\n",
    "for i in range(len(train_croped)):\n",
    "    o = im.open('./train_reshaped/tr%d.jpg' % (i))\n",
    "    o_arr = np.array(o)\n",
    "    o_arr = o_arr / 255\n",
    "    X_train.append(o_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for i in range(len(test_croped)):\n",
    "    o = im.open('./test_reshaped/te%d.jpg' % (i))\n",
    "    o_arr = np.array(o)\n",
    "    o_arr = o_arr / 255\n",
    "    X_test.append(o_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
