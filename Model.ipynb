{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "\n",
    "y_train = K.utils.np_utils.to_categorical(y_train)\n",
    "y_test = K.utils.np_utils.to_categorical(y_test)\n",
    "y_valid = K.utils.np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Dropout, GRU, BatchNormalization, Input, Reshape, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # enable dynamic GPU memory allocation\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "def SE_Block(input):\n",
    "    # Squeeze\n",
    "    glob_ave_pool = GlobalAveragePooling2D()(input)\n",
    "    input_shape = input.shape[-1]\n",
    "\n",
    "    # Excitation\n",
    "    f = input_shape // 16\n",
    "\n",
    "    fc1 = Dense(f, activation = 'relu', use_bias = False)(glob_ave_pool)\n",
    "    fc2 = Dense(input_shape, activation = 'sigmoid', use_bias=False)(fc1)\n",
    "    \n",
    "    # Scaling\n",
    "    re = Reshape((1, 1, input_shape))(fc2)\n",
    "\n",
    "    output = input * re\n",
    "\n",
    "    return output\n",
    "\n",
    "def Double_GRU(input_shape):\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    conv1 = Conv2D(32, (3,3))(input)\n",
    "    batch1 = BatchNormalization()(conv1)\n",
    "    act1 = Activation('relu')(batch1)\n",
    "    se1 = SE_Block(act1)\n",
    "\n",
    "    conv2 = Conv2D(32, (3,3))(se1)\n",
    "    batch2 = BatchNormalization()(conv2)\n",
    "    act2 = Activation('relu')(batch2)\n",
    "    se2 = SE_Block(act2)\n",
    "\n",
    "    conv3 = Conv2D(64, (3,3), strides=(2, 2))(se2)\n",
    "    batch3 = BatchNormalization()(conv3)\n",
    "    act3 = Activation('relu')(batch3)\n",
    "    se3 = SE_Block(act3)\n",
    "\n",
    "    conv4 = Conv2D(64, (3,3))(se3)\n",
    "    batch4 = BatchNormalization()(conv4)\n",
    "    act4 = Activation('relu')(batch4)\n",
    "    se4 = SE_Block(act4)\n",
    "\n",
    "    conv5 = Conv2D(128, (3,3))(se4)\n",
    "    batch5 = BatchNormalization()(conv5)\n",
    "    act5 = Activation('relu')(batch5)\n",
    "    se5 = SE_Block(act5)\n",
    "\n",
    "    reshape = Reshape((441, 128))(se5)\n",
    "    dropout = Dropout(0.1)(reshape)\n",
    "\n",
    "    gru1 = GRU(80, return_sequences = True)(dropout)\n",
    "    gru2 = GRU(50)(gru1)\n",
    "\n",
    "    reshape2 = Reshape((5, 10))(gru2)\n",
    "\n",
    "    output = Dense(10, activation = 'softmax')(reshape2)\n",
    "\n",
    "    model = Model(input, output, name = 'Double_gru')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 140, 1)\n",
    "model = Double_GRU(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend  as K\n",
    "def sequence_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the proportion of sequences for which the entire sequence was correctly predicted.\n",
    "    Assumes that each example in the batch has the same length.\n",
    "    \"\"\"\n",
    "    # Compute the element-wise equality between y_true and y_pred\n",
    "    equal_elements = K.cast(K.all(K.equal(y_true, K.round(y_pred)), axis=-1), K.floatx())\n",
    "\n",
    "    # Compute the sequence-wise equality\n",
    "    sequence_equal = K.all(equal_elements, axis=-1)\n",
    "\n",
    "    # Compute the mean sequence accuracy across the batch\n",
    "    sequence_accuracy = K.mean(sequence_equal)\n",
    "\n",
    "    return sequence_accuracy\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience = 20,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "\n",
    "model_hist = model.fit(\n",
    "    x = X_train, y = y_train,\n",
    "    epochs = 100,\n",
    "    batch_size = 64,\n",
    "    validation_data = (X_valid, y_valid),\n",
    "    callbacks = [early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(model_hist.history[\"loss\"])\n",
    "plt.plot(model_hist.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(model_hist.history[\"accuracy\"])\n",
    "plt.plot(model_hist.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Model accuracy : ', score[1])\n",
    "print('Model loss : ', score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "pred_label = tf.argmax(y_pred, axis = -1)\n",
    "pred_label = np.array(pred_label)\n",
    "\n",
    "label = tf.argmax(y_test, axis = -1)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_flat = np.ravel(pred_label)\n",
    "y_pred_flat = np.ravel(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test_flat, y_pred_flat)\n",
    "\n",
    "print(classification_report(y_test_flat, y_pred_flat))\n",
    "print(accuracy_score(y_test_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.subplots(figsize=(10, 6))\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt=\"d\")\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "ax.yaxis.set_ticklabels(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum value in each row\n",
    "max_values = np.max(y_pred, axis=2)\n",
    "\n",
    "# Create a new array with 1 where the maximum value is found, and 0 elsewhere\n",
    "result = np.where(y_pred == max_values[..., np.newaxis], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sequence_accuracy(y_test, result)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
